
import os
from dotenv import load_dotenv
from openai import OpenAI
import json

load_dotenv()

client = OpenAI(api_key=os.getenv("APIPPL"), base_url="https://api.perplexity.ai")

async def is_recipe(text):
    print(" Sprawdzam, czy tekst jest przepisem kulinarnym...")
    try:
        messages = [
            {
                "role": "system",
                "content": "Jeste asystentem AI, kt贸ry ocenia, czy dany tekst jest przepisem kulinarnym."
            },
            {
                "role": "user",
                "content": f"Przeanalizuj poni偶szy tekst i sprawd藕 w polskim internecie, czy jest istnieje taki przepis kulinarny. Odpowiedz sowem 'True', jeli tekst jest przepisem kularnym, lub sowem 'False', jeli tekst nie jest przepisem. Nie podawaj 偶adnych dodatkowych wyjanie ani informacji, odpowiedz tylko wartoci logiczn True albo False. Sprawdzaj teskt tylko na polskojzycznych stronach internetowych lub danych.\n\nTekst: {text}"
            }
        ]

        response = client.chat.completions.create(
            model="llama-3-sonar-large-32k-online",
            messages=messages,
            temperature=0.2,
            max_tokens=1,
            top_p=1,
        )
        response_message = response.choices[0].message.content.strip()
        print(response_message)
        return response_message.lower() == 'true'
    except Exception as e:
        print(f"Wystpi bd: {e}")
        return False

async def recipeGenerator(recipe):
    print(" wysylam przepis do sformatowania przez gpt")
    try:
        messages = [
            {
                "role": "system",
                "content": "Jeste ekspertem kulinarnym, kt贸ry analizuje tekst przepisu i zwraca dane w formacie JSON."
            },
            {
                "role": "user",
                "content": f"Na podstawie poni偶szego tekstu dotyczcego przepisu, prosz przygotowa dane i zwr贸ci tylko i wycznie w formacie JSON z poni偶sz struktur:\n\n{{\n  \"nazwa\": \"\",\n  \"czas_przygotowania\": 0,\n  \"zdjecie_url\": \"\",\n  \"opis\": \"\",\n  \"instrukcja\": \"\",\n  \"skladniki\": [],\n  \"zrodlo_url\":\"\n}}\n\nInstrukcje:\n\n1. Wyodrbnij nazw przepisu z tekstu i wpisz j w polu \"nazwa\". Jeli nazwa nie jest podana, pozostaw to pole puste.\n\n2. Jeli czas przygotowania jest podany w tekcie, wpisz go w minutach w polu \"czas_przygotowania\". W przeciwnym razie pozostaw 0.\n\n3. Jeli w tekcie znajduje si adres URL zdjcia przepisu, wpisz go w polu \"zdjecie_url\". W przeciwnym razie pozostaw puste pole.\n\n4. Wyodrbnij opis przepisu z tekstu i wpisz go w polu \"opis\". Jeli opis nie jest podany, pozostaw to pole puste.\n\n5. Wyodrbnij instrukcj przygotowania z tekstu i wpisz j w polu \"instrukcja\". Jeli instrukcja jest podzielona na kroki, pocz je w jeden cigy tekst. Jeli instrukcja nie jest podana, pozostaw to pole puste.\n\n6. Wyodrbnij list skadnik贸w z tekstu i wpisz je w polu \"skladniki\" jako tablic. Jeli skadniki nie s podane, pozostaw pust tablic []. Skadniki maj by podane w tablicy oddzielone przecinkami, np. [\"250g makaronu\", \"300g wody\", \"450g mietanki\"]\n\n7. Tekst przepisu:\n{recipe}\n\nPamitaj, aby zwr贸ci dane tylko w formacie JSON zgodnie z powy偶sz struktur, bez dodatkowych informacji. Nie zmieniaj nazw kluczy. Wszystkie wartoci typu string musz by w podw贸jnych cudzysowach, a tablica skadnik贸w musi by poprawnie sformatowana. Tekst w wartociach ma by dobrze sformatowany, poprawny stylistycznie i ortograficznie."
            }
        ]

        response = client.chat.completions.create(model="llama-3-sonar-large-32k-chat",
        messages=messages,
        temperature=0.2,
        max_tokens=4096,
        top_p=1)
        response_message = response.choices[0].message.content
        print(response_message)
        return response_message
    except Exception as e:
        print(f"Wystpi bd: {e}")
        return {}
